{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Annotator.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNW6oTPO4XKYztJFREF7uxl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_BsOJZeHMtJM","colab_type":"text"},"source":["### Import Dependencies"]},{"cell_type":"code","metadata":{"id":"Y2rqfI_jMrhJ","colab_type":"code","colab":{}},"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","# Import component classes (TagPredictor and ManualTagger)\n","from TagPredictor import TagPredictor\n","from ManualTagger import ManualTagger"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vPwHSTJ04Ud4","colab_type":"text"},"source":["### Class Definition"]},{"cell_type":"code","metadata":{"id":"7-bLE6Q532mo","colab_type":"code","colab":{}},"source":["'''\n","@file       Annotator.ipynb\n","@date       2020/08/03\n","@brief      Top level class that defines the annotation tool and active learning algorithm\n","'''\n","\n","\n","'''\n","@brief  NLP classification annotation tool\n","'''\n","class Annotator:\n","    labeledDB = None\n","    unlabelDB = None\n","\n","\n","    def __init__(self, labeledDatafile, unlabeledDatafile):\n","        # Create labeled and unlabeled databases\n","        self.labeledDB, self.unlabeledDB = self.createDatabases(labeledDatafile, unlabeledDatafile)\n","    \n","\n","    '''\n","    @brief      Performs preprocessing and cleaning on a sentence\n","    @param      text    String that contains the raw sentence\n","    @return     text    String that contains the cleaned sentence\n","    '''\n","    def cleanText(self, text):\n","        ## Change all instance of featureString to text\n","\n","        # Replace newline and tab characters with spaces\n","        featureString = featureString.replace('\\n', ' ')\n","        featureString = featureString.replace('\\t', ' ')\n","\n","        # Convert all letters to lowercase\n","        featureString = featureString.lower()\n","        \n","        # Strip all punctuation\n","        #table = str.maketrans('', '', string.punctuation)\n","        #featureString = featureString.translate(table)\n","\n","        # Remove all non-ASCII characters\n","        #featureString = featureString.encode(encoding='ascii', errors='ignore').decode('ascii')\n","\n","        # Split feature string into a list to perform processing on each word\n","        wordList = featureString.split()\n","\n","        # Remove all stop words\n","        stop_words = set(stopwords.words('english'))\n","        wordList = [word for word in wordList if not word in stop_words]\n","\n","        # Remove all words to contain non-ASCII characters\n","        wordList = [word for word in wordList if is_ascii(word)]\n","\n","        # Remove all leading/training punctuation, except for '$'\n","        punctuation = '!\"#%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n","        wordList = [word.strip(punctuation) for word in wordList]\n","\n","        # Replace all numbers with ######## identifier\n","        # Replace all costs with $$$$$$$$ identifier\n","        wordList = ['########' if (word.replace('.','').isdigit()) \\\n","                    else '$$$$$$$$' if (word.replace('.','').replace('$','').isdigit()) \\\n","                    else word \\\n","                    for word in wordList]\n","        #wordList = ['########' if (word.replace('.','').isdigit()) else word for word in wordList]\n","        #wordList = ['########' if (word.translate(table).isdigit()) else word for word in wordList]\n","\n","        # Reconstruct featureString\n","        # If it is empty, do not add this sample to the final output\n","        featureString = ' '.join(wordList)\n","\n","        return text\n","\n","\n","    '''\n","    @brief      Loads data from CSV files into Pandas dataframes and performs cleanText() on all columns\n","    @param      labeledDatafile     Labeled data CSV file\n","    @param      unlabeledDatafile   Unlabeled data CSV file\n","    @return     labeledDB           Pandas dataframe of the labeled data\n","    @return     unlabeledDB         Pandas dataframe of the unlabeled data\n","    '''\n","    def createDatabases(self, labeledDatafile, unlabeledDatafile):\n","        # Load CSV files as Pandas dataframes\n","\n","        # Combine topic title and leading comment columns\n","\n","        # Apply cleanText() to all columns with this:\n","        dataframe['Column Name'] = dataframe['Column Name'].apply(lambda x: cleanText(x))\n","\n","\n","    '''\n","    @brief      Demonstration function to run the entire annotator application\n","    @param      \n","    @return     None\n","    '''\n","    def runApplication(self, classifier):\n","        # Create labeled and unlabeled databases\n","        self.labeledDB, self.unlabeledDB = self.createDatabases(labeledDatafile, unlabeledDatafile)\n","\n","        # Train tagPredictor\n","\n","        # Predict tags for all unlabeled topics\n","\n","        # Continue running the active learning loop as long as there are still low-confidence topics\n","            # Log tagging statistics\n","            \n","            # Pass low-confidence topics to the manual tagger\n","\n","            # Add manually tagged topics to the labeled database\n","\n","            # Train tagPredictor\n","\n","            # Predict tags for all unlabeled topics\n","\n","\n","\n","\n","if __name__ == '__main__':\n","    pass\n"],"execution_count":null,"outputs":[]}]}