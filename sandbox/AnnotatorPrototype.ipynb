{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AnnotatorPrototype.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DjjB_R1-0JKE"},"source":["### Mount Google Drive and install import_ipynb"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WfsZ7x2snpEX","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1598297163142,"user_tz":240,"elapsed":17110,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}},"outputId":"9d668f4b-e530-4514-fa1c-30f2ac4c5e44"},"source":["#!pip install import_ipynb\n","\n","from google.colab import drive\n","from os.path import join\n","\n","# Mounting location on runtime for GDrive\n","ROOT = '/content/drive'\n","\n","# Mount GDrive on the runtime\n","drive.mount(ROOT)\n","\n","# Create and change directory to workspace folder\n","WORKING_PATH = '/content/drive/My Drive/Github/ml-team1-july2020'\n","%cd {WORKING_PATH}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/Github/ml-team1-july2020\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_BsOJZeHMtJM"},"source":["### Import Dependencies"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Y2rqfI_jMrhJ","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598297167315,"user_tz":240,"elapsed":21274,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}},"outputId":"f077b7d1-76f9-4da9-9e88-006e4b9b0998"},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Github/ml-team1-july2020/sandbox/TagPredictor')\n","sys.path.append('/content/drive/My Drive/Github/ml-team1-july2020/sandbox/ManualTagger')\n","\n","# Import component notebooks in other folders\n","#import import_ipynb\n","\n","from sandbox.TagPredictor.classifier import Classifier\n","from sandbox.TagPredictor.classifier_SVM import Classifier_SVM\n","from sandbox.TagPredictor.multilabelclassifier_SVM import MultilabelClassifier_SVM\n","from sandbox.TagPredictor.TagPredictor import TagPredictor\n","from sandbox.ManualTagger.ManualTagger import ManualTagger\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import re\n","import ast\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import hamming_loss\n","from sklearn.metrics import accuracy_score\n","\n","# Set Pandas display options\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_colwidth', 20)\n","pd.set_option('display.width', None)\n","pd.set_option('display.expand_frame_repr', False)   # Disable wrapping\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vPwHSTJ04Ud4"},"source":["### Class Definition"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7-bLE6Q532mo","colab":{},"executionInfo":{"status":"ok","timestamp":1598298687708,"user_tz":240,"elapsed":585,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}}},"source":["'''\n","@file       Annotator.ipynb\n","@date       2020/08/03\n","@brief      Top level class that defines the annotation tool and active learning algorithm\n","'''\n","\n","\n","'''\n","@brief  NLP classification annotation tool\n","'''\n","class Annotator:\n","    groundTruthDB = None            # Pandas dataframe of all data with ground truth labels\n","    labeledDB = None                # Pandas dataframe of labeled data\n","    unlabeledDB = None              # Pandas dataframe of unlabeled data\n","\n","    tagPredictor = None             # TagPredictor object\n","    manualTagger = None             # ManualTagger object\n","\n","    confidenceThreshold = 0.95      # Prediction confidence threshold to determine if a topic should be passed to ManualTagger\n","\n","\n","    def __init__(self, datafile):\n","        # Create databases\n","        self.groundTruthDB, self.labeledDB, self.unlabeledDB = self.createDatabases(datafile)\n","\n","        # Set up ManualTagger\n","        self.manualTagger = ManualTagger(self.groundTruthDB)\n","    \n","\n","    '''\n","    @brief      Performs preprocessing and cleaning on a sentence\n","    @param      text    String that contains the raw sentence\n","    @return     text    String that contains the cleaned sentence\n","    '''\n","    def cleanText(self, text):\n","        def is_ascii(s):\n","            return all(ord(c) < 128 for c in s)\n","        \n","        # Remove URLs\n","        text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n","\n","        # Replace newline and tab characters with spaces\n","        text = text.replace('\\n', ' ')\n","        text = text.replace('\\t', ' ')\n","\n","        # Convert all letters to lowercase\n","        text = text.lower()\n","        \n","        # Strip all punctuation\n","        #table = str.maketrans('', '', string.punctuation)\n","        #text = text.translate(table)\n","\n","        # Remove all non-ASCII characters\n","        #text = text.encode(encoding='ascii', errors='ignore').decode('ascii')\n","\n","        # Split feature string into a list to perform processing on each word\n","        wordList = text.split()\n","\n","        # Remove all stop words\n","        #stop_words = set(stopwords.words('english'))\n","        #wordList = [word for word in wordList if not word in stop_words]\n","\n","        # Remove all words to contain non-ASCII characters\n","        wordList = [word for word in wordList if is_ascii(word)]\n","\n","        # Remove all leading/training punctuation, except for '$'\n","        punctuation = '!\"#%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n","        wordList = [word.strip(punctuation) for word in wordList]\n","\n","        # Replace all numbers with ######## identifier\n","        # Replace all costs with $$$$$$$$ identifier\n","        wordList = ['########' if (word.replace('.','').isdigit()) \\\n","                    else '$$$$$$$$' if (word.replace('.','').replace('$','').isdigit()) \\\n","                    else word \\\n","                    for word in wordList]\n","        #wordList = ['########' if (word.replace('.','').isdigit()) else word for word in wordList]\n","        #wordList = ['########' if (word.translate(table).isdigit()) else word for word in wordList]\n","\n","        # Reconstruct text\n","        # If it is empty, do not add this sample to the final output\n","        text = ' '.join(wordList)\n","\n","        return text\n","\n","\n","    '''\n","    @brief      Loads data from CSV files into Pandas dataframes and performs cleanText() on all columns\n","    @param      datafile        CSV file with all data\n","    @return     groundTruthDB   Pandas dataframe of all data with ground truth labels\n","    @return     labeledDB       Pandas dataframe of the labeled data\n","    @return     unlabeledDB     Pandas dataframe of the unlabeled data\n","    '''\n","    def createDatabases(self, datafile):\n","        # Load CSV file as ground truth database\n","        groundTruthDB = pd.read_csv(datafile)\n","\n","        # Combine topic title and leading comment columns\n","        groundTruthDB['Bag_of_Words'] = groundTruthDB['Topic Title'] + groundTruthDB['Leading Comment']\n","        groundTruthDB['Bag_of_Words'] = groundTruthDB['Bag_of_Words'].str.strip().str.replace('   ', ' ').str.replace('  ', ' ')\n","\n","        groundTruthDB = groundTruthDB.drop(columns=['Topic Title', 'Leading Comment', 'Unnamed: 0'])\n","        \n","        # Apply cleanText() to all columns with this:\n","        groundTruthDB['Bag_of_Words'] = groundTruthDB['Bag_of_Words'].apply(lambda x: self.cleanText(x))\n","\n","        '''\n","        #create an offset value\n","        offset = 0\n","        #the total number of unique comments\n","        total = len(groundTruthDB)\n","        for index, entry in enumerate(groundTruthDB['Bag_of_Words']):\n","            #create a duplicate if post has multiple tags\n","            tag_list = ast.literal_eval(groundTruthDB.loc[index, 'Tags'])\n","            text = groundTruthDB.loc[index,'Bag_of_Words']\n","            while (isinstance(tag_list, list) and len(tag_list) > 1):\n","                #print(index)\n","                #sets the tag for the duplicate to a string\n","                groundTruthDB.loc[total+offset, 'Tags'] = tag_list.pop()\n","                #Adds the duplicate to the end of the pandas dataframe\n","                groundTruthDB.loc[total+offset, 'Bag_of_Words'] = text\n","                offset = offset + 1\n","            #Changes the first tag to a string\n","            if (len(tag_list) == 1):\n","                groundTruthDB.loc[index, 'Tags'] = tag_list.pop()\n","            #Changes empty tags from lists to strings\n","            if (isinstance(groundTruthDB.loc[index, 'Tags'], list)):\n","                groundTruthDB.loc[index, 'Tags'] = ''\n","                # Not sure why this element is stored as '[]' instead of ''\n","        '''\n","\n","        # Filter out topics with no tags\n","        groundTruthDB = groundTruthDB[groundTruthDB['Tags'].map(len) > 2]\n","\n","        # Convert Tag column elements from strings to lists\n","        groundTruthDB['Tags'] = groundTruthDB.Tags.apply(lambda x: x[1:-1].split(','))\n","\n","        # Split ground truth database into labeled and unlabelled databases\n","        #mask = np.random.rand(len(groundTruthDB)) < 0.8\n","        #labeledDB = groundTruthDB[~mask]\n","        #unlabeledDB = groundTruthDB[mask]['Bag_of_Words']\n","\n","        groundTruthDB = groundTruthDB.sample(2000)\n","\n","        unlabeledDB, labeledDB = train_test_split(groundTruthDB, test_size=0.2)\n","        #unlabeledDB = unlabeledDB['Bag_of_Words']\n","\n","        return groundTruthDB, labeledDB, unlabeledDB\n","\n","\n","    '''\n","    @brief      Demonstration function to run the entire annotator application\n","    @param      \n","    @return     None\n","    '''\n","    def runApplication(self, classifier):\n","        # Create multilabel binarizer for metric calculations\n","        mlb = MultiLabelBinarizer()\n","\n","        # Set up TagPredictor object\n","        tagPredictor = TagPredictor(classifier, self.labeledDB)\n","\n","        # Train tagPredictor\n","        tagPredictor.train()\n","\n","        # Predict tags for all unlabeled topics\n","        tagList, confidenceList = tagPredictor.predict(self.unlabeledDB['Bag_of_Words'])\n","\n","        # Continue running the active learning loop as long as there are still low-confidence topics\n","        counter = 1\n","        print(min(confidenceList))\n","        print(max(confidenceList))\n","        while (any(p < self.confidenceThreshold for p in confidenceList) == True):\n","            # Log tagging statistics\n","            print('Active Learning Iteration ', counter)\n","            print('Labeled Database Size: ', len(self.labeledDB))\n","            print('Unlabeled Database Size: ', len(self.unlabeledDB))\n","            trueLabelIndicatorMatrix = mlb.fit_transform(self.unlabeledDB['Tags'])\n","            predictedLabelIndicatorMatrix = mlb.transform(tagList)\n","            print('Hamming Loss: ', hamming_loss(trueLabelIndicatorMatrix, predictedLabelIndicatorMatrix))\n","            print('Accuracy: ', accuracy_score(trueLabelIndicatorMatrix, predictedLabelIndicatorMatrix))\n","            \n","            # Get low-confidence topic indices\n","            lowConfIndices = [i for i in range(len(confidenceList)) if confidenceList[i] < self.confidenceThreshold]\n","\n","            # Pass low-confidence topics to the manual tagger\n","            lowConfTopics = self.unlabeledDB.iloc[lowConfIndices]\n","            #print(lowConfIndices)\n","            #print(lowConfTopics)\n","            labeledTopics = self.manualTagger.tagTopics(lowConfTopics)\n","\n","            # Add manually tagged topics to the labeled database\n","            self.labeledDB = pd.concat([self.labeledDB, labeledTopics], join='inner')\n","\n","            # Remove tagged topics from unlabeled database\n","            #self.unlabeledDB = self.unlabeledDB.drop(lowConfTopics)\n","\n","            cond = self.unlabeledDB['Bag_of_Words'].isin(lowConfTopics['Bag_of_Words'])\n","            print(len(self.unlabeledDB))\n","            print(len(lowConfTopics))\n","            self.unlabeledDB.drop(self.unlabeledDB[cond].index, inplace=True)\n","\n","            if (len(self.unlabeledDB) == 0):\n","                break\n","\n","            # Train tagPredictor with updated database\n","            tagPredictor = TagPredictor(classifier, self.labeledDB)\n","            tagPredictor.train()\n","\n","            # Predict tags for all unlabeled topics\n","            tagList, confidenceList = tagPredictor.predict(self.unlabeledDB['Bag_of_Words'])\n","\n","            counter += 1\n"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ziCVPa5-pK_0","colab_type":"text"},"source":["### Main"]},{"cell_type":"code","metadata":{"id":"J-DFjkzFpIZM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1598298968271,"user_tz":240,"elapsed":278865,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}},"outputId":"18b09523-cbe8-4646-8d60-f34ce3e9251a"},"source":["# Path to CSV datafile\n","datafile = '/content/drive/My Drive/Github/ml-team1-july2020/sandbox/Webscraper/StackOverflow_new_tags.csv'\n","\n","annotator = Annotator(datafile)\n","\n","annotator.runApplication(MultilabelClassifier_SVM)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n","Running SVM Classifier\n","Finished training\n","0.9079388586269761\n","0.9768445579706911\n","Active Learning Iteration  1\n","Labeled Database Size:  400\n","Unlabeled Database Size:  1600\n","Hamming Loss:  0.04971153846153846\n","Accuracy:  0.165\n","1600\n","1019\n","Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"stream","text":["Running SVM Classifier\n","Finished training\n","Active Learning Iteration  2\n","Labeled Database Size:  1419\n","Unlabeled Database Size:  581\n","Hamming Loss:  0.04355885078776645\n","Accuracy:  0.23235800344234078\n","581\n","101\n","Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"stream","text":["Running SVM Classifier\n","Finished training\n","Active Learning Iteration  3\n","Labeled Database Size:  1520\n","Unlabeled Database Size:  480\n","Hamming Loss:  0.040705128205128206\n","Accuracy:  0.2625\n","480\n","55\n","Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"stream","text":["Running SVM Classifier\n","Finished training\n","Active Learning Iteration  4\n","Labeled Database Size:  1575\n","Unlabeled Database Size:  425\n","Hamming Loss:  0.039095022624434386\n","Accuracy:  0.26823529411764707\n","425\n","26\n","Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"stream","text":["Running SVM Classifier\n","Finished training\n","Active Learning Iteration  5\n","Labeled Database Size:  1601\n","Unlabeled Database Size:  399\n","Hamming Loss:  0.038172353961827644\n","Accuracy:  0.2656641604010025\n","399\n","27\n","Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"stream","text":["Running SVM Classifier\n","Finished training\n","Active Learning Iteration  6\n","Labeled Database Size:  1628\n","Unlabeled Database Size:  372\n","Hamming Loss:  0.037944582299421006\n","Accuracy:  0.2903225806451613\n","372\n","10\n","Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"stream","text":["Running SVM Classifier\n","Finished training\n","Active Learning Iteration  7\n","Labeled Database Size:  1638\n","Unlabeled Database Size:  362\n","Hamming Loss:  0.038567785805354866\n","Accuracy:  0.27624309392265195\n","362\n","9\n","Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"stream","text":["Running SVM Classifier\n","Finished training\n","Active Learning Iteration  8\n","Labeled Database Size:  1647\n","Unlabeled Database Size:  353\n","Hamming Loss:  0.03802571366310743\n","Accuracy:  0.2776203966005666\n","353\n","3\n","Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"stream","text":["Running SVM Classifier\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-7565e2c579f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mannotator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnnotator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mannotator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunApplication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultilabelClassifier_SVM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-4df69f2f74d1>\u001b[0m in \u001b[0;36mrunApplication\u001b[0;34m(self, classifier)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# Train tagPredictor with updated database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mtagPredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeledDB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mtagPredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;31m# Predict tags for all unlabeled topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Github/ml-team1-july2020/sandbox/TagPredictor/TagPredictor.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_X_Tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Github/ml-team1-july2020/sandbox/TagPredictor/multilabelclassifier_SVM.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, Train_X_Tfidf, Train_Y, Test_X_Tfidf, Test_Y)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# fit the training dataset on the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiOutputClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_X_Tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# predict the labels on validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#predictions_SVM = self.model.predict(Test_X_Tfidf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, sample_weight)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    168\u001b[0m             delayed(_fit_estimator)(\n\u001b[1;32m    169\u001b[0m                 self.estimator, X, y[:, i], sample_weight)\n\u001b[0;32m--> 170\u001b[0;31m             for i in range(y.shape[1]))\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32msklearn/svm/_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"1clUyBhIpOgR","colab_type":"text"},"source":["### All test code below here"]},{"cell_type":"code","metadata":{"id":"Nkgm3CT6hKEW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"ok","timestamp":1598299038311,"user_tz":240,"elapsed":35986,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}},"outputId":"779904d0-051a-4133-fddc-034b44035ecc"},"source":["# Set up TagPredictor object\n","tagPredictor = TagPredictor(MultilabelClassifier_SVM, annotator.labeledDB)\n","\n","# Train tagPredictor\n","tagPredictor.train()\n","\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Initialized TagPredictor\n","Started training\n","[\" 'beautifulsoup'\" \" 'nlp'\" \" 'nltk'\" \" 'scrapy'\" \" 'selenium-webdriver'\"\n"," \" 'sentiment-analysis'\" \" 'splinter'\" \" 'text-classification'\"\n"," \" 'text-mining'\" \" 'tf-idf'\" \" 'web-scraping'\" \" 'word-embedding'\"\n"," \"'beautifulsoup'\" \"'nlp'\" \"'nltk'\" \"'scikit-learn'\" \"'scrapy'\"\n"," \"'selenium'\" \"'selenium-webdriver'\" \"'sentiment-analysis'\" \"'splinter'\"\n"," \"'text-classification'\" \"'text-mining'\" \"'tf-idf'\" \"'web-scraping'\"\n"," \"'word-embedding'\"]\n","Running SVM Classifier\n","Finished training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mEFR66ZImCGN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598299041168,"user_tz":240,"elapsed":33261,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}},"outputId":"43674cbe-419b-4681-dcae-98ebeca0b979"},"source":["# Predict tags for all unlabeled topics\n","tagList, confidenceList = tagPredictor.predict(annotator.unlabeledDB['Bag_of_Words'])\n","print(tagList)\n","print(confidenceList)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[(\"'text-classification'\",), (), (), (), (), (\"'selenium'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\"'scikit-learn'\",), (), (\"'sentiment-analysis'\",), (), (\"'sentiment-analysis'\",), (), (), (\"'scikit-learn'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (\"'scikit-learn'\",), (), (), (\"'text-classification'\",), (), (), (), (), (), (), (\"'scrapy'\",), (), (), (), (), (\" 'splinter'\", \"'splinter'\"), (\"'nlp'\",), (), (\"'sentiment-analysis'\",), (\"'sentiment-analysis'\",), (), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (\"'scrapy'\",), (\"'nltk'\",), (\"'tf-idf'\",), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (\" 'sentiment-analysis'\", \"'sentiment-analysis'\"), (), (), (), (), (), (), (), (\"'nltk'\",), (), (), (), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (), (\"'scrapy'\",), (), (\"'scikit-learn'\",), (), (\"'scikit-learn'\",), (\"'scikit-learn'\",), (), (), (\" 'word-embedding'\", \"'nlp'\", \"'word-embedding'\"), (), (), (), (), (), (\"'tf-idf'\",), (), (\"'nlp'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (\"'selenium'\",), (\"'word-embedding'\",), (), (), (\"'scrapy'\",), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\"'scikit-learn'\",), (), (\"'nlp'\",), (), (\"'nlp'\",), (), (), (), (), (\"'tf-idf'\",), (), (), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (\"'nlp'\",), (), (\"'scikit-learn'\",), (), (\"'scikit-learn'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\"'web-scraping'\",), (), (\"'sentiment-analysis'\",), (\"'scikit-learn'\",), (), (\"'word-embedding'\",), (), (\" 'beautifulsoup'\", \"'web-scraping'\"), (), (\"'beautifulsoup'\",), (), (\"'nlp'\",), (\"'web-scraping'\",), (\"'scikit-learn'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (\"'web-scraping'\",), (\"'nlp'\",), (\"'scikit-learn'\",), (\"'nltk'\",), (\"'scikit-learn'\",), (\" 'scrapy'\", \"'scrapy'\", \"'web-scraping'\"), (\" 'tf-idf'\", \"'tf-idf'\"), (\" 'tf-idf'\", \"'tf-idf'\"), (), (\"'selenium'\",), (), (\" 'tf-idf'\", \"'tf-idf'\"), (), (), (\"'web-scraping'\",), (\"'scrapy'\",), (\"'scrapy'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (\"'scrapy'\",), (\"'web-scraping'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\" 'tf-idf'\", \"'tf-idf'\"), (), (\"'scrapy'\",), (\"'nlp'\",), (), (\" 'scrapy'\", \"'scrapy'\"), (\"'nlp'\",), (\"'sentiment-analysis'\",), (), (\"'word-embedding'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (\"'selenium'\",), (), (\"'nlp'\",), (), (\"'web-scraping'\",), (\"'scikit-learn'\",), (), (\"'sentiment-analysis'\",), (), (), (), (\"'nlp'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (\" 'tf-idf'\", \"'tf-idf'\"), (\" 'tf-idf'\", \"'scikit-learn'\", \"'tf-idf'\"), (), (\"'scikit-learn'\",), (\"'web-scraping'\",), (\"'nlp'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\" 'tf-idf'\", \"'scikit-learn'\"), (), (), (\"'selenium'\",), (), (\" 'text-classification'\", \"'scikit-learn'\"), (\"'text-mining'\",), (), (), (\"'scikit-learn'\",), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (), (\"'scikit-learn'\",), (\"'sentiment-analysis'\",), (\"'word-embedding'\",), (\"'word-embedding'\",), (), (\"'scikit-learn'\",), (), (), (), (), (\"'scrapy'\",), (), (\"'selenium-webdriver'\",), (\"'scikit-learn'\",), (), (), (\" 'nltk'\", \"'nltk'\"), (), (), (), (\"'web-scraping'\",), (), (\"'scikit-learn'\",), (), (), (\" 'tf-idf'\", \"'scikit-learn'\"), (\"'scikit-learn'\",), (), (), (), (\"'scrapy'\",), (), (\"'nlp'\",), (), (), (), (\" 'splinter'\", \"'splinter'\"), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\"'nlp'\",), (), (\" 'word-embedding'\", \"'nlp'\", \"'word-embedding'\"), (), (\"'word-embedding'\",), (\"'scrapy'\",), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\" 'sentiment-analysis'\", \"'sentiment-analysis'\"), (), (\"'nlp'\",), (\" 'word-embedding'\", \"'nlp'\"), (\"'scikit-learn'\",), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (\"'scrapy'\",), (), (), (\"'scikit-learn'\",), (\"'scikit-learn'\",), (), (), (), (), (\" 'selenium-webdriver'\", \"'selenium'\"), (\"'scikit-learn'\",), (\"'text-mining'\",), (\" 'word-embedding'\", \"'nlp'\"), (\"'nlp'\",), (), (\"'tf-idf'\",), (\"'word-embedding'\",), (\"'nlp'\",), (\"'scikit-learn'\",), (), (\"'scrapy'\",), (), (\"'web-scraping'\",), (), (), (), (\"'scikit-learn'\",), (), (\"'scikit-learn'\",), (), (\"'text-mining'\",), (\"'nlp'\",), (\"'scrapy'\",), (), (\"'nlp'\",), (\"'text-mining'\",), (\"'selenium'\",), (), (), (\"'nlp'\",), (\" 'text-classification'\", \"'scikit-learn'\"), (\" 'selenium-webdriver'\", \"'selenium'\"), (), (), (\"'nlp'\",), (\"'sentiment-analysis'\",), (), (), (), (\"'nlp'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (\"'text-mining'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (\"'selenium'\",), (\"'nlp'\",), (\" 'word-embedding'\", \"'nlp'\"), (), (), (), (), (\"'scikit-learn'\",), (\" 'selenium-webdriver'\", \"'selenium'\"), (\"'text-classification'\",), (), (\"'scikit-learn'\", \"'word-embedding'\"), (\"'scikit-learn'\",), (), (\"'scikit-learn'\",), (\"'sentiment-analysis'\",), (), (\"'word-embedding'\",), (), (), (), (\" 'word-embedding'\", \"'nlp'\", \"'word-embedding'\"), (\"'scikit-learn'\",), (), (\"'scrapy'\",), (), (\"'splinter'\",)]\n","[0.97187827 0.96109997 0.96453344 0.95913497 0.96305842 0.96750262\n"," 0.98215765 0.95481124 0.96133801 0.97955286 0.96353576 0.96765282\n"," 0.95689299 0.97648467 0.95679054 0.97126285 0.9543514  0.97694909\n"," 0.96659648 0.95925977 0.95557778 0.96519793 0.96053656 0.96184053\n"," 0.96371371 0.95389264 0.96259509 0.96097681 0.96201565 0.96481638\n"," 0.96711007 0.95300674 0.97020289 0.96915138 0.96443709 0.96415572\n"," 0.96941314 0.9606169  0.97650096 0.96919719 0.95912434 0.96977441\n"," 0.95666056 0.95922885 0.96786541 0.96836122 0.95392601 0.97356737\n"," 0.96121689 0.96902855 0.95975382 0.9610094  0.98093563 0.96549298\n"," 0.96951863 0.96315393 0.97255198 0.95102161 0.9692116  0.96786651\n"," 0.98104444 0.96767873 0.96560951 0.97083808 0.95340561 0.97607903\n"," 0.96513019 0.9522317  0.96388385 0.98276131 0.95819505 0.96259574\n"," 0.96468449 0.97363175 0.97199952 0.96082765 0.96909447 0.9624657\n"," 0.95985427 0.9698498  0.9634416  0.95480515 0.96809043 0.95428248\n"," 0.96031163 0.96441999 0.98566345 0.96459374 0.97597916 0.96302525\n"," 0.96014921 0.97223342 0.96770252 0.949095   0.96673314 0.96989167\n"," 0.95544962 0.97377029 0.96944748 0.95210146 0.96791441 0.96452101\n"," 0.96734784 0.96372423 0.96493912 0.96373115 0.97053907 0.97108222\n"," 0.96615763 0.96260773 0.97657326 0.96263347 0.96703959 0.96127837\n"," 0.98003397 0.96407077 0.95882102 0.96906749 0.96807977 0.95798575\n"," 0.95569391 0.95672114 0.96979386 0.96524315 0.96038634 0.98335583\n"," 0.96270143 0.96877164 0.95314082 0.94964614 0.96145412 0.97289353\n"," 0.97430357 0.97612381 0.97867614 0.96950303 0.96332087 0.96991437\n"," 0.9662744  0.96499825 0.96477668 0.96287496 0.96511516 0.97522047\n"," 0.96232793 0.96404171 0.97830658 0.96037439 0.95290518 0.95470664\n"," 0.95758025 0.96220606 0.97130202 0.96853299 0.9600508  0.96274908\n"," 0.96962056 0.96417334 0.9709134  0.95849313 0.97249561 0.95260563\n"," 0.96544171 0.97281396 0.95283363 0.9518893  0.96824625 0.97124886\n"," 0.95971204 0.96343574 0.96025315 0.96276711 0.9607215  0.98135264\n"," 0.96740482 0.96649735 0.97535224 0.96388389 0.96825588 0.96623329\n"," 0.96158377 0.97455076 0.9581726  0.95695354 0.95344081 0.96624371\n"," 0.97406797 0.97189133 0.96512361 0.97617486 0.95730998 0.97747256\n"," 0.97081047 0.97729543 0.97392359 0.96910852 0.96535418 0.98430015\n"," 0.96232032 0.97041344 0.95934572 0.96203546 0.97032044 0.96959116\n"," 0.95860172 0.96588183 0.9739702  0.96527609 0.9610637  0.96258987\n"," 0.9548028  0.96954616 0.96771434 0.96623131 0.97382369 0.96801824\n"," 0.95183152 0.9743524  0.96689499 0.97194928 0.96493816 0.96126477\n"," 0.96133499 0.9601151  0.96498863 0.97152828 0.96253825 0.96351631\n"," 0.96873485 0.96998226 0.96499081 0.96775276 0.95322443 0.96356441\n"," 0.97130227 0.97005266 0.96866364 0.97344346 0.97912714 0.95578834\n"," 0.95689567 0.96493299 0.96445491 0.97363568 0.94969344 0.95586456\n"," 0.97493427 0.97092815 0.95458552 0.96355836 0.97903212 0.9582436\n"," 0.96115146 0.95763182 0.97236567 0.96657577 0.96263061 0.9592914\n"," 0.96438329 0.97176728 0.97612684 0.96615527 0.95669138 0.98105052\n"," 0.96333442 0.97241627 0.9644813  0.97136126 0.95787734 0.9691677\n"," 0.97161334 0.96616138 0.96591733 0.96884578 0.9703931  0.96017365\n"," 0.96508321 0.96599205 0.9645735  0.98229837 0.97871569 0.97295775\n"," 0.98133511 0.95653735 0.96586274 0.95789965 0.96564577 0.96562598\n"," 0.9665936  0.96570989 0.97143741 0.95967085 0.97826065 0.95953232\n"," 0.96422794 0.96233815 0.9685327  0.96159853 0.97423159 0.96198868\n"," 0.97104048 0.96730823 0.9812019  0.95297714 0.95570618 0.96512955\n"," 0.97080206 0.97047812 0.96163382 0.97156936 0.97722017 0.98504223\n"," 0.96912953 0.96183583 0.96385179 0.96867379 0.96230122 0.9665665\n"," 0.96569243 0.95932678 0.96599928 0.96288066 0.96378457 0.9611784\n"," 0.95731018 0.97793997 0.95505197 0.96139226 0.95531926 0.96545613\n"," 0.97332261 0.96935156 0.95477106 0.96497991 0.95338824 0.96877685\n"," 0.95763318 0.96831366 0.97182491 0.96263425 0.98165171 0.95554339\n"," 0.96769513 0.95766962 0.96492424 0.97866164 0.96821845 0.97289374\n"," 0.96034853 0.96046587]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UYagkhXNY_DM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598299041169,"user_tz":240,"elapsed":25680,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}},"outputId":"e6dd463e-65b4-44ac-b7b1-aa4205145b08"},"source":["from sklearn.preprocessing import MultiLabelBinarizer\n","mlb = MultiLabelBinarizer()\n","\n","trueLabelIndicatorMatrix = mlb.fit_transform(annotator.unlabeledDB['Tags'])\n","predictedLabelIndicatorMatrix = mlb.transform(tagList)\n","\n","from sklearn.metrics import hamming_loss\n","from sklearn.metrics import accuracy_score\n","print(hamming_loss(trueLabelIndicatorMatrix, predictedLabelIndicatorMatrix))\n","print(accuracy_score(trueLabelIndicatorMatrix, predictedLabelIndicatorMatrix))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["0.03802197802197802\n","0.28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IkfKTY0KBgM-","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1598297172202,"user_tz":240,"elapsed":26111,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}}},"source":["print(trueLabelIndicatorMatrix.shape)\n","print(predictedLabelIndicatorMatrix.shape)\n","\n","print(max(confidenceList))\n","print(min(confidenceList))\n","print(len(tagList))\n","print(len(annotator.groundTruthDB))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QpBjcZSuMLVz","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1598297172203,"user_tz":240,"elapsed":26108,"user":{"displayName":"kdglider stemaway","photoUrl":"","userId":"14511763866677580222"}}},"source":["from operator import itemgetter \n","import numpy as np\n","a = ['abc', 'def', 'ghi', 'this', 'is', 'great']\n","b = np.array([0,1,0,1,0,1])\n","c = [i for i in range(len(b)) if b[i] == 1]\n","print([a[i] for i in range(len(b)) if b[i] == 1])\n","print(itemgetter(*c)(a))"],"execution_count":null,"outputs":[]}]}